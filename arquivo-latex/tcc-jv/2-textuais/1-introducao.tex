\chapter{Introdução}
\label{cap:introducao}

A crescente adoção de dispositivos vestíveis (\textit{wearables}) como ferramentas de monitoramento contínuo de saúde tem impulsionado pesquisas que buscam relacionar dados comportamentais objetivos — como padrões de atividade física, sono, frequência cardíaca e uso de smartphones — com indicadores subjetivos de bem-estar, como a qualidade de vida. Estudos recentes demonstraram que modelos de \gls{ML} aplicados a esses dados podem alcançar métricas de desempenho aparentemente promissoras, com valores de RMSE entre 6 e 7 pontos na predição de domínios físico e psicológico da qualidade de vida \cite{oliveira2025healful}. Essa perspectiva sugere a viabilidade de sistemas preditivos capazes de auxiliar na identificação precoce de indivíduos em risco ou na personalização de intervenções de saúde.

No entanto, a validade desses resultados depende fundamentalmente da metodologia de validação empregada. Trabalhos anteriores frequentemente utilizaram estratégias como \textit{KFold} com embaralhamento aleatório (\textit{shuffle=True}), permitindo que registros de um mesmo participante apareçam tanto no conjunto de treino quanto no de teste \cite{gharaee2024har}. Essa prática introduz \textit{data leakage}, fenômeno no qual o modelo "memoriza" características individuais durante o treinamento e as recupera no teste, inflando artificialmente as métricas de desempenho sem, contudo, demonstrar capacidade real de generalização para novos indivíduos \cite{kaliappan2023impact}. Esse problema se torna ainda mais crítico quando se considera que a heterogeneidade individual — diferenças basais entre participantes — representa a maior fonte de variabilidade em estudos de qualidade de vida, superando amplamente a variabilidade temporal intra-participante \cite{gharaee2024har}.

Além disso, a presença de multicolinearidade entre as variáveis preditoras — comum em datasets com dezenas de \textit{features} comportamentais correlacionadas, como passos e calorias, ou diferentes métricas de variabilidade da frequência cardíaca — pode comprometer tanto a estabilidade quanto a interpretabilidade dos modelos \cite{he2023multicollinearity}. Técnicas de redução de multicolinearidade, como a remoção iterativa de variáveis com \textit{Variance Inflation Factor} (VIF) elevado, têm potencial para melhorar o desempenho preditivo, mas seu impacto raramente é quantificado de forma rigorosa em estudos da área \cite{shariff2023hybrid}.

Diante desse cenário, torna-se essencial avaliar se os resultados reportados na literatura refletem genuína capacidade preditiva ou são consequência de falhas metodológicas que inflam artificialmente o desempenho dos modelos \cite{tougui2021impact}. Essas falhas incluem, por exemplo, o vazamento de informações entre conjuntos de treino e teste (\textit{data leakage}), que ocorre quando registros de um mesmo participante aparecem em ambos os conjuntos, permitindo que o modelo "memorize" características individuais em vez de aprender padrões generalizáveis. A aplicação de estratégias de validação rigorosas, como o \textit{GroupKFold} \cite{pedregosa2024groupkfold}, que garante separação completa de participantes entre os conjuntos de treino e teste, permite investigar a real capacidade de generalização dos modelos. Ademais, a comparação sistemática entre diferentes abordagens de pré-processamento (com e sem redução de multicolinearidade) e diferentes arquiteturas de modelos (tradicionais versus avançados) possibilita identificar quais fatores efetivamente contribuem para a performance preditiva e quais são meras ilusões estatísticas.

Este trabalho tem como objetivo comparar e analisar diferentes cenários na predição de qualidade de vida a partir de dados de \textit{wearables}, variando sistematicamente quanto à estratégia de validação (KFold \textit{versus} GroupKFold), tratamento de multicolinearidade (dataset original \textit{versus} pós-VIF) e complexidade dos modelos (tradicionais \textit{versus} avançados). Especificamente, buscamos: (1) quantificar o impacto do \textit{data leakage} na inflação das métricas de desempenho \cite{hatzivassiloglou2023effects}; (2) avaliar a contribuição da redução de multicolinearidade via VIF \cite{datacamp2024vif}; (3) verificar se modelos avançados (\textit{ensemble} e \textit{boosting}) superam modelos tradicionais quando submetidos a validação rigorosa; e (4) explicar, por meio da decomposição de variância, as razões estruturais que limitam a generalização em estudos com poucos participantes.

A relevância deste estudo reside em três contribuições principais. Primeiro, do ponto de vista metodológico, demonstramos de forma quantitativa o impacto do \textit{data leakage} (inflação de 131–143\% no RMSE) e evidenciamos a necessidade de validação com GroupKFold em estudos de séries temporais individuais \cite{kapoor2023leakage}. Segundo, do ponto de vista técnico, quantificamos o ganho de desempenho proporcionado pela redução de multicolinearidade (melhoria de 27–29\% via VIF), fornecendo evidências empíricas da importância do pré-processamento rigoroso. Terceiro, do ponto de vista da reprodutibilidade científica, apresentamos um \textit{framework} de validação replicável e transparente, reportando não apenas RMSE e MAE, mas também $R^2$ — métrica que revela a real capacidade explicativa dos modelos e que, neste estudo, resultou consistentemente negativa em todos os cenários sem \textit{data leakage}, indicando que os modelos populacionais testados erram mais que o baseline de simplesmente prever a média \cite{bergmeir2025forecasting}.

Os resultados obtidos evidenciam que 83\% da variabilidade na qualidade de vida é explicada por diferenças entre participantes (\textit{between-participants}), enquanto apenas 12\% é atribuída a variações temporais (\textit{within-participants}) \cite{sliwinski2023iiv}. Essa desproporção, combinada com o tamanho amostral limitado (35 participantes, aproximadamente 7 por \textit{fold} de teste no GroupKFold), torna inviável a construção de modelos populacionais capazes de generalizar para novos indivíduos. A utilização de modelos avançados como XGBoost, LightGBM e CatBoost resulta em melhoria de 7,5–16,8\% em relação aos modelos tradicionais, confirmando que algoritmos mais sofisticados podem extrair padrões adicionais mesmo em cenários desafiadores. Entretanto, esta melhoria não é suficiente para superar o problema fundamental de dados: todos os cenários rigorosos apresentaram $R^2$ negativo, variando entre $-0,37$ e $-2,14$ \cite{bergmeir2025forecasting}.

Os detalhes deste trabalho está organizado no restante deste documento da seguinte forma: o Capítulo \ref{cap:fundamentacao} apresenta a fundamentação teórica sobre qualidade de vida, \textit{wearables}, técnicas de \gls{ML} e validação cruzada; o Capítulo \ref{cap:metodologia} detalha o dataset Healful \cite{oliveira2025healfuldataset}, o pipeline de pré-processamento (imputação, VIF, tratamento de \textit{outliers}), os cinco cenários experimentais e os modelos avaliados; o Capítulo \ref{cap:resultados} reporta as métricas de desempenho (RMSE, MAE, $R^2$), a decomposição de variância e as visualizações comparativas; e o Capítulo \ref{cap:conclusao} sintetiza as principais descobertas, discute as implicações para a área e aponta direções para trabalhos futuros, incluindo a necessidade de datasets com mais de 100 participantes \cite{kourtis2023wearables} ou a adoção de abordagens personalizadas (\textit{within-participant modeling}) em vez de modelos populacionais \cite{ervasti2025gait}.
